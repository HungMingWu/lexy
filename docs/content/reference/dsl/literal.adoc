---
header: "lexy/dsl/literal.hpp"
entities:
  "lexy::dsl::lit": lit
  "LEXY_LIT": lit
  "lexy::dsl::lit_c": lit_c
  "lexy::dsl::lit_b": lit_b
  "lexy::dsl::lit_cp": lit_cp
---

[.lead]
Token rules that match exact characters.

[#lit]
== Token rule `lexy::dsl::lit`

{{% interface %}}
----
namespace lexy::dsl
{
    template <auto Str>
    constexpr _token-rule_ auto lit;
}

#define LEXY_LIT(Str) lexy::dsl::lit<Str>
----

[.lead]
`lit` is a {{% token-rule %}} that matches the specified sequence of characters.

Requires::
  `Str` is a string literal of some character type `CharT`, that is compatible with the input {{% encoding %}}, i.e. it must be one of the two cases described below.
Matching::
  1. If `CharT` is the same as character type of the input {{% encoding %}}, `lit<Str>` compares each code unit of `Str` in order with the next code unit of the reader and consumes it.
     It is not checked whether `Str` is a well-formed string (e.g. that it contains no https://en.wikipedia.org/wiki/UTF-8#Invalid_sequences_and_error_handling[ill-formed UTF-8]),
     and no https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization[normalization] or other https://en.wikipedia.org/wiki/Unicode_equivalence[equivalence checking] is done.
  2. Otherwise, if `CharT` is `char`, `Str` must only contain ASCII characters (i.e. `0x00-0x7F`).
    `lit<Str>` converts each ASCII character to the input encoding with a simply `static_cast` and then proceeds as done in case 1.
Errors::
  {{% docref "lexy::expected_literal" %}}: if one code unit did not compare equal or the reader reached the end of the input.
  Its `.string()` is `Str`, its `.index()` is the index of the code unit where the mismatch/missing one occurred, and its `.position()` is the reader position where it started to match the literal.
Parse tree::
  Single token node with the {{% docref "lexy::predefined_token_kind" %}} `lexy::literal_token_kind`.

The macro `LEXY_LIT(Str)` is equivalent to `lit<Str>`, except that it also works on older compilers that do not support C++20's extended NTTPs.
Use this instead of `lit<Str>` if you need to support them.

{{% playground-example lit "Hello World!" %}}

{{% playground-example lit_ascii "A different character type, but only ASCII characters" %}}

{{% playground-example lit_utf8 "UTF-8 encoded string literal" %}}

TIP: When using non-ASCII characters in a `lit<Str>` rule, it is best to specify code points with the `\uXXXX` escape sequences and normalize the input before passing it to `lexy`.

NOTE: As a token rule, `lit<Str>` tries to skip whitespace directly following the literal.
Use {{% docref "lexy::dsl::no_whitespace" %}} to prevent that.

NOTE: While `lit<"int">` would happily consume a prefix of `"integer"`, {{% docref "lexy::dsl::keyword" %}}[`<"int">(id)`], for a matching `id`, would not.

[#lit_c]
== Token rule `lexy::dsl::lit_c`

{{% interface %}}
----
namespace lexy::dsl
{
    template <auto C>
    constexpr _token-rule_ auto lit_c;
}
----

[.lead]
`lit_c<C>`, where `C` is a character type, is equivalent to `lit<Str>`, where `Str` is the string literal consisting of the single character `C`.

The same restrictions on character type apply.

TIP: Literals that match common {{% docref punctuators %}} are pre-defined.

[#lit_b]
== Token rule `lexy::dsl::lit_b`

{{% interface %}}
----
namespace lexy::dsl
{
    template <unsigned char ... C>
    constexpr _token-rule_ auto lit_b;
}
----

[.lead]
`lit_b<C...>` matches a sequence of bytes.

Requires::
  The input encoding is {{% docref "lexy::byte_encoding" %}} unless all characters are ASCII.
Matching::
  Matches and consumes the exact sequence of bytes.
Errors::
  {{% docref "lexy::expected_literal" %}}: if one code unit did not compare equal or the reader reached the end of the input.
  Its `.string()` is the string of the bytes converted to the correct character type, its `.index()` is the index of the code unit where the mismatch/missing one occurred, and its `.position()` is the reader position where it started to match the literal.
Parse tree::
  Single token node with the {{% docref "lexy::predefined_token_kind" %}} `lexy::literal_token_kind`.

TIP: Use {{% docref "lexy::dsl::bom" %}} to match a byte-order mark.

[#lit_cp]
== Token rule `lexy::dsl::lit_cp`

{{% interface %}}
----
template <char32_t CodePoint>
constexpr _token-rule_ auto lit_cp;
----

[.lead]
`lit_cp` is a {{% token-rule %}} that matches the specific `CodePoint`.

Requires::
  * `CodePoint` is the value of a scalar code point (i.e. non-surrogate and not out of bounds).
  * The input {{% encoding %}} is ASCII, UTF-8, UTF-16, or UTF-32.
    If it is ASCII, `CodePoint` is an ASCII character.
Matching::
  Matches and consumes the code units that encode `CodePoint` in the encoding of the input.
  For ASCII and UTF-32, this is a single code unit, for UTF-8 up to four code units, and for UTF-16 up to two code units.
Errors::
  {{% docref "lexy::expected_literal" %}}: if one code unit did not compare equal or the reader reached the end of the input.
  Its `.string()` is the encoded version of `CodePoint`, its `.index()` is the index of the code unit where the mismatch/missing one occurred, and its `.position()` is the reader position where it started to match the literal.
Parse tree::
  Single token node with the {{% docref "lexy::predefined_token_kind" %}} `lexy::literal_token_kind`.

It behaves identical to {{% docref "lexy::dsl::lit" %}} where `Str` is determined by encoding `CodePoint` in the encoding of the input.

{{% playground-example "code_point_lit" "Match a smiley face" %}}

NOTE: The caveats of {{% docref "lexy::dsl::lit" %}} regarding whitespace skipping and keywords apply here as well.

CAUTION: If the input contains an ill-formed code unit sequence, this is not checked by this rule;
it simply compares each code unit.

